## **(1)**

Analyse the Tetragonula bees data set in R-package prabclus. This
data set gives genetic data for 236 Tetragonula (Apidae) bees from Australia and
Southeast Asia. The data give pairs of alleles for 13 diploid microsatellite loci
(these can be thought of as positions of genes, each characterised by two alleles).
The interest here is in clustering the bees in order to find different bee species. A
species is characterised by having a similar genetic makeup, whereas different species
should be separated. In this form, the alleles are coded by numbers (every locus has a six digit number,
with the first three digits referring to the first allele, and the digits 4-6 referring to
the second allele). The data set needs some preprocessing in order to make it ready
for work, particularly, `tai$distmat` is now a matrix of genetic distances.

  * Using `tai$distmat`, compute an MDS and show the MDS plot. Try out different dissimilarity-based cluster analysis methods and decide which one you
think is best here. Also choose a number of clusters and visualise your final
clustering using the MDS. Give reasons for your choices.

  * Try out the following alternative way of clustering the data: Take the points
generated by the MDS and apply k-means clustering or Ward's method to
them. Again choose a number of clusters (you may use the gap statistic for
this).
What are advantages and disadvantages of this approach compared to the
hierarchical clustering? Do you think that this clustering is ultimately better?
Do you think it would be better, for this task, to produce an MDS solution
with p > 2?


## **(2)**

For the olive oil data with standardised variables, compute the following
clusterings and compare them according to their similarity (ARI) with both the
macro areas and the regions.
  * k-means with number of clusters estimated by the gap statistic
  
  * Ward's method with number of clusters estimated by the ASW
  
  * Single Linkage using Euclidean, Manhattan, and Mahalanobis distance with
number of clusters estimated by the ASW

  * Average Linkage using Euclidean, Manhattan, and Mahalanobis distance with
number of clusters estimated by the ASW

  * Complete Linkage using Euclidean, Manhattan, and Mahalanobis distance with
number of clusters estimated by the ASW

  * Partitioning Around Medoids using Euclidean, Manhattan, and Mahalanobis
distance with number of clusters estimated by the ASW.


## **(4)**

Read the paper 
> Ester, M., Kriegel, H.-P., Sander, J. and Xu, X. "A density-based algorithm for
discovering clusters in large spatial databases with noise". In Simoudis, E., Han,
J. and Fayyad, U.M. (eds.) Proceedings of the Second International Conference on
Knowledge Discovery and Data Mining (KDD-96) . Palo Alto, CA: AAAI Press, 226-231.

and answer the following questions:

  * Summarize in your own words what the DBSCAN method does
  * What are the advantages, according to the authors, of their DBSCAN method
compared with other clustering methods, particularly those that you already
know? Do you think that the authors' arguments are convincing?
  * Find out how to run DBSCAN in R and apply it to the Bundestag data. You will need to make some decisions
(and/or experiments) about tuning parameters. Comment on the results.
